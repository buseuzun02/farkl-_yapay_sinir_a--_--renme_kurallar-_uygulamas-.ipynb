{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5f987-5421-4a6d-8a3d-5653e65dabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def bipolar_binary(x):\n",
    "    return 1 if x >= 0 else -1\n",
    "\n",
    "def bipolar_continuous(x):\n",
    "    return (2 / (1 + np.exp(-x))) - 1\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return x if x > 0 else alpha * x\n",
    "\n",
    "def tanh_function(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def bipolar_continuous_derivative(y):\n",
    "    return 0.5 * (1 - y**2)\n",
    "\n",
    "def hebb_learning(weights, inputs, activation_function, alpha=1):\n",
    "    print(\"Initial Weights:\", weights)\n",
    "\n",
    "    for step, x in enumerate(inputs, start=1):\n",
    "        # Net input calculation\n",
    "        u = np.dot(weights, x)\n",
    "        f_u = activation_function(u)  # Activation function applied to net input\n",
    "        delta_w = alpha * f_u * x\n",
    "\n",
    "        # Update weights\n",
    "        weights += delta_w\n",
    "\n",
    "        # Print step-by-step results\n",
    "        print(f\"Step {step}:\")\n",
    "        print(f\"  Input: {x}\")\n",
    "        print(f\"  Net Input (u): {u}\")\n",
    "        print(f\"  Activation Output (f(u)): {f_u}\")\n",
    "        print(f\"  Delta Weights (\\u0394W): {delta_w}\")\n",
    "        print(f\"  Updated Weights: {weights}\\n\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "def perceptron_learning(weights, inputs, targets, alpha=1):\n",
    "    print(\"Initial Weights:\", weights)\n",
    "\n",
    "    for step, (x, target) in enumerate(zip(inputs, targets), start=1):\n",
    "        # Net input calculation\n",
    "        u = np.dot(weights, x)\n",
    "        y = bipolar_binary(u)  # Step activation function\n",
    "        delta_w = alpha * (target - y) * x\n",
    "\n",
    "        # Update weights\n",
    "        weights += delta_w\n",
    "\n",
    "        # Print step-by-step results\n",
    "        print(f\"Step {step}:\")\n",
    "        print(f\"  Input: {x}\")\n",
    "        print(f\"  Target: {target}\")\n",
    "        print(f\"  Net Input (u): {u}\")\n",
    "        print(f\"  Output (y): {y}\")\n",
    "        print(f\"  Delta Weights (\\u0394W): {delta_w}\")\n",
    "        print(f\"  Updated Weights: {weights}\\n\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "def delta_rule(weights, inputs, targets, alpha=1, lambd=1):\n",
    "    print(\"Initial Weights:\", weights)\n",
    "\n",
    "    for step, (x, target) in enumerate(zip(inputs, targets), start=1):\n",
    "        # Net input calculation\n",
    "        u = np.dot(weights, x)\n",
    "        f_u = (2 / (1 + np.exp(-lambd * u))) - 1  # Bipolar continuous activation function\n",
    "        f_u_derivative = bipolar_continuous_derivative(f_u)  # Derivative of bipolar continuous\n",
    "        delta_w = alpha * (target - f_u) * f_u_derivative * x\n",
    "\n",
    "        # Update weights\n",
    "        weights += delta_w\n",
    "\n",
    "        # Print step-by-step results\n",
    "        print(f\"Step {step}:\")\n",
    "        print(f\"  Input: {x}\")\n",
    "        print(f\"  Target: {target}\")\n",
    "        print(f\"  Net Input (u): {u}\")\n",
    "        print(f\"  Activation Output (f(u)): {f_u}\")\n",
    "        print(f\"  Derivative (f'(u)): {f_u_derivative}\")\n",
    "        print(f\"  Delta Weights (\\u0394W): {delta_w}\")\n",
    "        print(f\"  Updated Weights: {weights}\\n\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "def widrow_hoff_rule(weights, inputs, targets, alpha=1, lambd=0.01):\n",
    "    print(\"Initial Weights:\", weights)\n",
    "\n",
    "    for step, (x, target) in enumerate(zip(inputs, targets), start=1):\n",
    "        # Net input calculation\n",
    "        u = np.dot(weights, x)\n",
    "        delta_w = alpha * (target - u) * x   # Adding regularization term\n",
    "\n",
    "        # Update weights\n",
    "        weights += delta_w\n",
    "\n",
    "        # Print step-by-step results\n",
    "        print(f\"Step {step}:\")\n",
    "        print(f\"  Input: {x}\")\n",
    "        print(f\"  Target: {target}\")\n",
    "        print(f\"  Net Input (u): {u}\")\n",
    "        print(f\"  Delta Weights (\\u0394W): {delta_w}\")\n",
    "        print(f\"  Updated Weights: {weights}\\n\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Get user inputs for initial weights\n",
    "initial_weights = np.array(list(map(float, input(\"Enter initial weights (comma-separated): \").split(\",\"))))\n",
    "\n",
    "# Get user inputs for input vectors\n",
    "num_inputs = int(input(\"Enter the number of input vectors: \"))\n",
    "inputs = []\n",
    "for i in range(num_inputs):\n",
    "    vector = np.array(list(map(float, input(f\"Enter input vector {i + 1} (comma-separated): \").split(\",\"))))\n",
    "    inputs.append(vector)\n",
    "\n",
    "# Get user inputs for targets if required\n",
    "targets_required = input(\"Do you need to provide target values? (yes/no): \").strip().lower() == \"yes\"\n",
    "targets = []\n",
    "if targets_required:\n",
    "    targets = list(map(float, input(\"Enter target values (comma-separated): \").split(\",\")))\n",
    "\n",
    "# Select learning rule\n",
    "print(\"\\nSelect Learning Rule:\")\n",
    "print(\"1. Hebb Rule\")\n",
    "print(\"2. Perceptron Learning Rule\")\n",
    "print(\"3. Delta Rule\")\n",
    "print(\"4. Widrow-Hoff Rule\")\n",
    "rule_choice = int(input(\"Enter your choice (1-4): \"))\n",
    "\n",
    "# Select activation function if required\n",
    "activation_function = None\n",
    "if rule_choice in [1, 3]:\n",
    "    print(\"\\nSelect Activation Function:\")\n",
    "    print(\"1. Step Function\")\n",
    "    print(\"2. Sigmoid\")\n",
    "    print(\"3. Bipolar Binary\")\n",
    "    print(\"4. Bipolar Continuous\")\n",
    "    print(\"5. ReLU\")\n",
    "    print(\"6. Leaky ReLU\")\n",
    "    print(\"7. Tanh\")\n",
    "    choice = int(input(\"Enter your choice (1-7): \"))\n",
    "\n",
    "    activation_functions = {\n",
    "        1: step_function,\n",
    "        2: sigmoid,\n",
    "        3: bipolar_binary,\n",
    "        4: bipolar_continuous,\n",
    "        5: relu,\n",
    "        6: lambda x: leaky_relu(x, alpha=0.01),\n",
    "        7: tanh_function\n",
    "    }\n",
    "\n",
    "    activation_function = activation_functions.get(choice, None)\n",
    "    if activation_function is None:\n",
    "        print(\"Invalid activation function choice. Exiting program.\")\n",
    "        exit()\n",
    "\n",
    "# Learning rate and lambda input\n",
    "alpha = float(input(\"Enter learning rate (alpha): \"))\n",
    "lambd = 0\n",
    "if rule_choice in [3, 4]:\n",
    "    lambd = float(input(\"Enter lambda (regularization term): \"))\n",
    "\n",
    "# Apply the selected learning rule\n",
    "if rule_choice == 1:\n",
    "    final_weights = hebb_learning(initial_weights, inputs, activation_function, alpha)\n",
    "elif rule_choice == 2:\n",
    "    final_weights = perceptron_learning(initial_weights, inputs, targets, alpha)\n",
    "elif rule_choice == 3:\n",
    "    final_weights = delta_rule(initial_weights, inputs, targets, alpha, lambd)\n",
    "elif rule_choice == 4:\n",
    "    final_weights = widrow_hoff_rule(initial_weights, inputs, targets, alpha, lambd)\n",
    "else:\n",
    "    print(\"Invalid learning rule choice. Exiting program.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Final Weights:\", final_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da950d0-b8e6-4f5b-835d-f2d8bea7d756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
